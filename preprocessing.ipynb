{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from glob import glob as glob\n",
    "import os\n",
    "from neo import io\n",
    "import seaborn as sb\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams[\"font.size\"]= 12\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# functions for PSTH\n",
    "from scipy.signal import gaussian\n",
    "from scipy.ndimage import filters\n",
    "def rate_binning(spike_times,time_bins,binsize):\n",
    "    average = np.zeros((len(spike_times),len(time_bins)))\n",
    "    for i,t in enumerate(time_bins):\n",
    "        \n",
    "        for chan in range(len(spike_times)):\n",
    "            include = (spike_times[chan]>=t) & (spike_times[chan]<(t+binsize))\n",
    "            average[chan,i] = sum(include)/binsize\n",
    "    return average\n",
    "\n",
    "def smoothing(signal,sd,binsize):\n",
    "    ''' aplly gaussian filter per trial'''\n",
    "    kernel = gaussian(signal.shape[-1],sd/binsize)\n",
    "    ga = np.zeros(signal.shape)\n",
    "    if len(signal.shape)>3:\n",
    "        for dim1 in range(signal.shape[0]):\n",
    "            for dim2 in range(signal.shape[1]):\n",
    "                for dim3 in range(signal.shape[2]):\n",
    "                    ga[dim1,dim2,dim3,:] = filters.convolve1d(signal[dim1,dim2,dim3,:], kernel/kernel.sum())\n",
    "    else:\n",
    "        for dim1 in range(signal.shape[0]):\n",
    "            for dim2 in range(signal.shape[1]):\n",
    "                ga[dim1,dim2,:] = filters.convolve1d(signal[dim1,dim2,:], kernel/kernel.sum())\n",
    "                \n",
    "    return ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed data and extract sequence variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "animal_id = 'A11' # A11, H07\n",
    "exp = 'classical' # 'wang or classical\n",
    "out_path = '/Volumes/Bellet/Local_Global/processedData/%s/'%animal_id # path to the data\n",
    "\n",
    "# load preprocessed data\n",
    "df = pd.read_pickle(os.path.join(out_path,'%s_stims_spikes_dataframe.pkl'%(animal_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PFC_MU', 'PPC_MU', 'PFC_SU', 'PPC_SU', 'TrialID', 'ItemID', 'StimID', 'StimName', 'StimOn', 'blockID', 'blockType', 'date', 'StimDur', 'ISIDur', 'RewardOn']\n",
      "Recording dates: ['20200226' '20200228' '20200305' '20200306' '20200311' '20200312']\n"
     ]
    }
   ],
   "source": [
    "# extract basic variables\n",
    "dates = np.unique(df.date)\n",
    "ndates = len(dates)\n",
    "nitems = np.max(df.ItemID)\n",
    "stimID = np.unique(df.StimID)\n",
    "nstim = len(stimID)\n",
    "print(list(df.keys()))\n",
    "print('Recording dates:',dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute PSTH from spike times; only last stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 20200226  PFC\n",
      "Day: 20200228  PFC\n",
      "Day: 20200305  PFC\n",
      "Day: 20200306  PFC\n",
      "Day: 20200311  PFC\n",
      "Day: 20200312  PFC\n"
     ]
    }
   ],
   "source": [
    "# compute psth of every stim presented\n",
    "\n",
    "sf = 30000; # sampling frequency\n",
    "tmin = -0.3 # sec, before each stim\n",
    "tmax = 1.6 # sec, after each stim\n",
    "nch = len(df.PFC_MU[0])\n",
    "\n",
    "# create PSTH\n",
    "binsize = 0.025 # sec\n",
    "stepsize = 0.025 # sec, if stepsize=binsize: no overlap of bins\n",
    "sd = 0.05 # standard deviation of gaussian kernel\n",
    "time_bins = np.arange(tmin,tmax,stepsize)\n",
    "time_bins_gauss = time_bins[int(4*sd/binsize):-int(4*sd/binsize)]\n",
    "nbins = len(time_bins)\n",
    "\n",
    "for date in dates:\n",
    "\n",
    "    np.save(os.path.join(out_path,'time_bins_%s.npy'%date),time_bins)\n",
    "    np.save(os.path.join(out_path,'time_bins_gauss_%s.npy'%date),time_bins_gauss)\n",
    "    \n",
    "    # get conditions\n",
    "    last_item = np.where((df.ItemID==3) & (df.date==date))[0]\n",
    "    Ntrials = len(last_item)\n",
    "\n",
    "    # bin spikes from all channels and trials\n",
    "    \n",
    "    #######################\n",
    "    # PFC\n",
    "    print('Day:',date,' PFC')\n",
    "    Rb_last = np.zeros((Ntrials,nch,nbins))\n",
    "    for tr in range(Ntrials):\n",
    "        ind = last_item[tr]\n",
    "        Rb_last[tr,:] = rate_binning(df['PFC_MU'].iloc[ind],time_bins,binsize)\n",
    "    np.save(os.path.join(out_path,'Rb_last_%s.npy'%date),Rb_last)\n",
    "    \n",
    "    # gaussian smoothing\n",
    "    Rb_last = smoothing(Rb_last,sd,binsize)[:,:,int(4*sd/binsize):-int(4*sd/binsize)] # cut borders: 4*sd\n",
    "    np.save(os.path.join(out_path,'Rb_last_gauss_%s.npy'%date),Rb_last)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET PSTH FROM whole sequence, \n",
    "# consider entire trials only\n",
    "sf = 30000; # sampling frequency\n",
    "tmin = -0.3 # sec, before sequence start\n",
    "tmax = 1.6 # sec, after last stim\n",
    "nch = len(df.PFC_MU[0])\n",
    "\n",
    "# create PSTH\n",
    "binsize = 0.025 # sec\n",
    "stepsize = 0.025 # sec, if stepsize=binsize: no overlap of bins\n",
    "sd = 0.05 # standard deviation of gaussian kernel\n",
    "\n",
    "\n",
    "for date in dates:\n",
    "\n",
    "    print('Day:',date)\n",
    "    if ~os.path.exists(os.path.join(out_path,'Rb_seq_%s.npy'%date)):\n",
    "        # get conditions\n",
    "        last_item = np.where((df.ItemID==3) & (df.date==date))[0]\n",
    "        Ntrials = len(last_item)\n",
    "    \n",
    "        soa = (int(df.StimDur.iloc[last_item[0]]) + int(df.ISIDur.iloc[last_item[0]]))/1000.0\n",
    "        time_bins = np.arange(tmin,3*soa+tmax,stepsize) # time bins for entire sequence\n",
    "        time_bins_gauss = time_bins[int(4*sd/binsize):-int(4*sd/binsize)]\n",
    "        nbins = len(time_bins)\n",
    "        \n",
    "        # bin spikes from all channels and trials\n",
    "        Rb = np.zeros((Ntrials,nch,nbins))\n",
    "        \n",
    "        for tr in range(Ntrials):\n",
    "            t = 0\n",
    "            for i in range(4): # go until 4 stim backwards to start with 1st\n",
    "                ind = last_item[tr]-3+i\n",
    "                if i==3:\n",
    "                    time_bins_single = np.arange(0,tmax,stepsize) # time bins around last stimulus\n",
    "                elif i==0:\n",
    "                    time_bins_single = np.arange(tmin,soa,stepsize) # time bins around 1st stimulus\n",
    "                else:\n",
    "                    time_bins_single = np.arange(0,soa,stepsize) # time bins around 2nd and 3rd stimulus\n",
    "                Rb[tr,:,t:t+len(time_bins_single)] = rate_binning(df['PFC_MU'].iloc[ind],time_bins_single,binsize)\n",
    "                t += len(time_bins_single)\n",
    "        np.save(os.path.join(out_path,'Rb_seq_%s.npy'%date),Rb)\n",
    "        np.save(os.path.join(out_path,'time_bins_seq_%s.npy'%date),time_bins)\n",
    "        \n",
    "        # gaussian smoothing\n",
    "        Rb = smoothing(Rb,sd,binsize)[:,:,int(4*sd/binsize):-int(4*sd/binsize)] # cut borders: 4*sd\n",
    "        np.save(os.path.join(out_path,'Rb_seq_gauss_%s.npy'%date),Rb)\n",
    "        np.save(os.path.join(out_path,'time_bins_seq_gauss_%s.npy'%date),time_bins_gauss)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
